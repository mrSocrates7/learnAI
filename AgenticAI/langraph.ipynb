{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Agents in LangGraph\n",
        "- LangGraph is introduced by LangChain which is an open source framework for building LLM applications.\n",
        "- LangGraph allows to create highly controllable agents\n",
        "- Research papers used\n",
        "  - https://arxiv.org/pdf/2210.03629.pdf\n",
        "  - https://arxiv.org/pdf/2303.17651.pdf\n",
        "  - https://arxiv.org/pdf/2401.08500.pdf\n",
        "  "
      ],
      "metadata": {
        "id": "4S2U5Z56Q-T4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Agents from Scratch without frameworks\n",
        "- Agent we are going to build is based on the ReAct paper"
      ],
      "metadata": {
        "id": "g0o7WYzT12p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing ReAct Agent from scratch\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import httpx\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
        ")\n",
        "\n",
        "chat_completion.choices[0].message.content\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, system=\"\"):\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    def __call__(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        result = self.execute()\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return result\n",
        "\n",
        "    def execute(self):\n",
        "        completion = client.chat.completions.create(\n",
        "                        model=\"gpt-4o\",\n",
        "                        temperature=0,\n",
        "                        messages=self.messages)\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "average_dog_weight:\n",
        "e.g. average_dog_weight: Collie\n",
        "returns average weight of a dog when given the breed\n",
        "\n",
        "Example session:\n",
        "\n",
        "Question: How much does a Bulldog weigh?\n",
        "Thought: I should look the dogs weight using average_dog_weight\n",
        "Action: average_dog_weight: Bulldog\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: A Bulldog weights 51 lbs\n",
        "\n",
        "You then output:\n",
        "\n",
        "Answer: A bulldog weights 51 lbs\n",
        "\"\"\".strip()\n",
        "\n",
        "def calculate(what):\n",
        "    return eval(what)\n",
        "\n",
        "def average_dog_weight(name):\n",
        "    if name in \"Scottish Terrier\":\n",
        "        return(\"Scottish Terriers average 20 lbs\")\n",
        "    elif name in \"Border Collie\":\n",
        "        return(\"a Border Collies average weight is 37 lbs\")\n",
        "    elif name in \"Toy Poodle\":\n",
        "        return(\"a toy poodles average weight is 7 lbs\")\n",
        "    else:\n",
        "        return(\"An average dog weights 50 lbs\")\n",
        "\n",
        "known_actions = {\n",
        "    \"calculate\": calculate,\n",
        "    \"average_dog_weight\": average_dog_weight\n",
        "}\n",
        "\n",
        "abot = Agent(prompt)\n",
        "\n",
        "result = abot(\"How much does a toy poodle weigh?\")\n",
        "print(result)\n",
        "\n",
        "result = average_dog_weight(\"Toy Poodle\")\n",
        "\n",
        "next_prompt = \"Observation: {}\".format(result)\n",
        "abot(next_prompt)\n",
        "abot.messages\n",
        "abot = Agent(prompt)\n",
        "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
        "What is their combined weight\"\"\"\n",
        "abot(question)\n",
        "\n",
        "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Border Collie\"))\n",
        "print(next_prompt)\n",
        "abot(next_prompt)\n",
        "\n",
        "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Scottish Terrier\"))\n",
        "print(next_prompt)\n",
        "abot(next_prompt)\n",
        "\n",
        "next_prompt = \"Observation: {}\".format(eval(\"37 + 20\"))\n",
        "print(next_prompt)\n",
        "\n",
        "\n",
        "abot(next_prompt)\n",
        "\n",
        "# Adding loop to automate\n",
        "\n",
        "action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action\n",
        "\n",
        "def query(question, max_turns=5):\n",
        "    i = 0\n",
        "    bot = Agent(prompt)\n",
        "    next_prompt = question\n",
        "    while i < max_turns:\n",
        "        i += 1\n",
        "        result = bot(next_prompt)\n",
        "        print(result)\n",
        "        actions = [\n",
        "            action_re.match(a)\n",
        "            for a in result.split('\\n')\n",
        "            if action_re.match(a)\n",
        "        ]\n",
        "        if actions:\n",
        "            # There is an action to run\n",
        "            action, action_input = actions[0].groups()\n",
        "            if action not in known_actions:\n",
        "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
        "            print(\" -- running {} {}\".format(action, action_input))\n",
        "            observation = known_actions[action](action_input)\n",
        "            print(\"Observation:\", observation)\n",
        "            next_prompt = \"Observation: {}\".format(observation)\n",
        "        else:\n",
        "            return\n",
        "\n",
        "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
        "What is their combined weight\"\"\"\n",
        "query(question)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oryjS-_vAjJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangGraph Components\n",
        "- LangChain: Prompts\n",
        "  - reusable prompts\n",
        "- LangChain: Tools\n",
        "  - TavilySearchTool\n",
        "- Nodes : Agents or functions\n",
        "  -\n",
        "- Edges: Connect nodes\n",
        "- Conditional Edges: decisions\n",
        "- State: StateGraph\n",
        "  - Agent state is accessible to all parts of the graph\n",
        "  - It is local to the graph\n",
        "  - Can be stored in a persistence layer\n",
        "\n",
        "#### Features of LangGraph\n",
        "- Cyclic Graphs\n",
        "- Persistence\n",
        "- Human-in-the loop\n",
        "\n"
      ],
      "metadata": {
        "id": "Cy4dAOQiEcLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMess\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tool.tavily_search import TavilySearchResults\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "print\n"
      ],
      "metadata": {
        "id": "wHNCAtmcLJI7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "langraph",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}