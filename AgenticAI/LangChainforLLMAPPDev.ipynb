{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain for LLM Application Development\n",
        "\n",
        "#### Components of Langchain\n",
        "- Models : Language models\n",
        "- Prompts\n",
        "- Indexes/Parsers\n",
        "- Chains\n",
        "- Agents"
      ],
      "metadata": {
        "id": "4S2U5Z56Q-T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade langchain\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n"
      ],
      "metadata": {
        "id": "VmFDoddU9fi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Memory\n",
        "- remember previous part of the conversation and feed to LLM to answer the next question accordingly\n",
        "- LLMs are stateless, each transaction is independent\n",
        "- Kinds of memory Lanchain provides\n",
        "  - ConversationBufferMemory\n",
        "    - Allows for storing messages and then extracts the messages in a variable\n",
        "  - ConversationBufferWindowMemory\n",
        "    - Keeps a list of the interactions of the conversation over time. It only uses the last K interactions\n",
        "  - ConversationTokenBufferMemory\n",
        "    - Keeps a buffer of recent interactions in memory and uses token length rathen than number of interactions to determine when to flush interactions\n",
        "  - ConversationSummaryMemory\n",
        "    - Creates a summary of the conversation over time\n",
        "- Also supports below memory types\n",
        "  - Vector data memory\n",
        "    - Stores text in a vector databse and retrieves the most relevant blocks of text\n",
        "  - Entity memories\n",
        "    - Using an LLM, it remembers details about specific entities\n",
        "  - Conventional databases like SQL etc"
      ],
      "metadata": {
        "id": "AUMkoYno3aaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.0)\n",
        "memory = CoversationBufferMemory()\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "conversation.predict(input=\"Hi, my name is Balu\")"
      ],
      "metadata": {
        "id": "_5u7a5qP5fqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chains\n",
        "- Building blocks of Langchain\n",
        "- LLMChain\n",
        "- Sequential Chains : Combines multiple chains where the output of one chain is the input of the next chain\n",
        "  - SimpleSequentialChain : Single input/output\n",
        "  - SequentialChain : Multiple inputs/outputs\n",
        "- RouterChain"
      ],
      "metadata": {
        "id": "_kODOP6udBVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "df = pd.read_csv('Data.csv')\n",
        "df.head()\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.8)\n",
        "\n",
        "#prompt template 1\n",
        "prompt1 = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name to describe a company that makes cheesecakes?\"\n",
        ")\n",
        "\n",
        "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
        "\n",
        "print(chain1.run())\n",
        "\n",
        "#prompt template 2\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"Write a catchphrase for the following company: {company_name}\"\n",
        ")\n",
        "\n",
        "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
        "\n",
        "# simple sequential chain\n",
        "simple_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
        "\n",
        "print(simple_chain.run())\n",
        "\n"
      ],
      "metadata": {
        "id": "50eWnuRGdQbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question and Answer over documents\n",
        "-"
      ],
      "metadata": {
        "id": "clTIJYhBk_lc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "SampleJupyterNotebook",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}