{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning, Recommenders, Reinforcement Learning\n",
        "\n",
        "## Unsupervised Learning\n",
        "- Clustering\n",
        "- Anomaly detection\n",
        "\n",
        "## Recommender systems\n",
        "- For example the adivertisements use recommender systems to show adds based on audience preferences\n",
        "\n",
        "## Reinforcement Learning\n",
        "- new and has less commercially implemented\n"
      ],
      "metadata": {
        "id": "4S2U5Z56Q-T4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering\n",
        "- In unsupervised learning we only have inputs but no output labels\n",
        "- Used to find interesting structure of the data and if data can be grouped into clusters\n",
        "- Applications\n",
        "  - Grouping similar news\n",
        "  - Market segmentation\n",
        "  - DNA Analysis\n",
        "  - Astronomical data analysis\n",
        "\n",
        "## K-means clustering algorithm\n",
        "- takes random guess of centers of the groups of clusters called cluster centroids\n",
        "- Go through the data and check to which centroid the data is closer to and map to them\n",
        "- recompute the centroids by taking the average of the distance from all points mapped to them\n",
        "- re check to which centroid the data is closer to and map to them\n",
        "- repeat until there are no changes or the algorithm is converged\n",
        "\n",
        "#### pseudocode of the K-means algorithm is as follows:\n",
        "\n",
        "centroids = kMeans_init_centroids(X, K)\n",
        "\n",
        "for iter in range(iterations):\n",
        "  - idx = find_closest_centroids(X, centroids)\n",
        "\n",
        "centroids = compute_centroids(X, idx, K)\n",
        "\n",
        "The inner-loop of the algorithm repeatedly carries out two steps:\n",
        "Assigning each training example  ùë•(ùëñ)\n",
        "  to its closest centroid, and\n",
        "Recomputing the mean of each centroid using the points assigned to it.\n",
        "\n",
        "\n",
        "#### Actual implementation steps\n",
        "- Randomly initialize K cluster centroids $Œº_1,Œº_2,......, Œº_k$\n",
        "- Repeat {\n",
        "  - Assign points to cluster centroids\n",
        "  - for i = 1 to m\n",
        "    - c(i) := index (from 1 to K) of cluster centroid closest to x(i)\n",
        "    min K ||x(i) - Œºk\n",
        "  - Move cluster centroids\n",
        "    - for k = 1 to K\n",
        "    Œºk = average (mean) of points assigned to cluster k\n",
        "}\n",
        "\n",
        "\n",
        "#### Optimization\n",
        "- Cost function : Distortion function\n",
        "  - $c^{(i)}$ = index of cluster (1, 2, ...., K) to which example $x^{(i)}$ is currently assigned\n",
        "  - $Œº_k$ = cluster centroid k\n",
        "  - $Œº_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned\n",
        "  - $J(c^{(1)}, ..., c^{(m)}, Œº_1, ..., Œº_k) = \\frac{1}{m}‚àë_{i=1}^m ||x^{(i)}- Œº_{c^{(i)}} ||^2$\n",
        "  - Repeat {\n",
        "    - Assign points to cluster centroids\n",
        "    - for i=1 to m\n",
        "        - $c^{(i)} := index of cluster centroid closest to x^{(i)}$\n",
        "    - Move cluster centroids\n",
        "    - for k=1 to K\n",
        "      - $Œº_k$ := average of points in cluster k\n",
        "  }\n",
        "\n",
        "#### Initializing K-means\n",
        "  - How to randomly initialize the centroids location at the beginning\n",
        "  - Randomly pick K training examples and set the centroids equal to those examples\n",
        "  - repeat it for different examples\n",
        "  - Calculate cost function for various randomly picked centroids and pick the ones with less cost\n",
        "\n",
        "\n",
        "#### Choosing the number of clusters\n",
        "- Elbow method\n",
        "  - run K-means for various values of K (number of clusters) and calculate cost function\n",
        "  - plot the graph between cost function and number of clusters\n",
        "  - pick the number at the elbow of the curve\n",
        "  - Don't choose K just to minimize cost function\n",
        "- Other technique\n",
        "  - Evaluate K-means based on how well it performs on that later purpose\n",
        "  -\n",
        "\n"
      ],
      "metadata": {
        "id": "PGSPJ2Kx6TcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection\n",
        "- Finding unusual events\n",
        "- Density Estimation\n",
        "- Examnple usecases\n",
        "  - Fraud detection\n",
        "  - Manufacturing\n",
        "  - Monitoring computers in a data center\n",
        "\n",
        "\n",
        "#### Gaussian distribution / Normal Distribution\n",
        "- If x is a random number, probability of x is determined by a Gaussian with mean Œº, variance $œÉ^2$\n",
        "- $p(x)=\\frac{1}{\\sqrt{2\\pi}œÉ}e^{\\frac{-(x-Œº)^2}{2œÉ^2}}$\n",
        "- $Œº = \\frac{1}{m}‚àë_{i=1}^mx^{(i)}$\n",
        "- $œÉ^2 = \\frac{1}{m}‚àë_{i=1}^m(x^{(i)}-Œº)^2$\n",
        "\n",
        "## Anomaly detection algorithm\n",
        "- Training set: {$\\vec X^{(1)}, \\vec X^{(2)}, ..., \\vec X^{(m)}$}\n",
        "- Each example $\\vec X^{(i)}$ has n features\n",
        "- $p(\\vec x = p(x_1; Œº_1, œÉ_1^2)*p(x_2; Œº_2, œÉ_2^2)*p(x_3; Œº_3, œÉ_3^2)* ... * p(x_n; Œº_n, œÉ_n^2)$\n",
        "- Also written as: $p(\\vec x) = ‚àè_{j=1}^n p(x_j; Œº_j, œÉ_j^2)$\n",
        "- Algorithm\n",
        "  - Choose n features $x_i$ that you think might be indicative of anomalous examples\n",
        "  - Fit parameters $Œº_1, ..., Œº_n, œÉ_1^2, ..., œÉ_n^2$\n",
        "  - $Œº_j = \\frac{1}{m}‚àë_{i=1}^mx_j^{(i)}$\n",
        "  - $œÉ_j^2 = \\frac{1}{m}‚àë_{i=1}^m(x_j^{(i)}-Œº_j)^2$\n",
        "  - Vectorized\n",
        "  - $\\vec Œº = \\frac{1}{m}‚àë_{i=1}^m\\vec x^{(i)}$\n",
        "  - Given new example x, compute p(x)\n",
        "  - $p(\\vec x) = ‚àè_{j=1}^n p(x_j; Œº_j, œÉ_j^2) = ‚àè_{j=1}^n\\frac{1}{\\sqrt{2\\pi}œÉ_j}e^{\\frac{-(x_j-Œº_j)^2}{2œÉ_j^2}}$\n",
        "  - Anomaly if $p(x)<œµ$\n",
        "\n",
        "\n",
        "#### Developing and evaluating an anomaly detection system\n",
        "- Real-number evaluation\n",
        "  - let there are 10000 non anomalous examples and 20 anomalous examples\n",
        "  - Build training and test sets as below\n",
        "    - Training set : 6000 non anomalous examples\n",
        "    - Crossvalidation set : 2000 non anomalous, 10 anomalous examples\n",
        "    - Test set : 2000 non anomalous, 10 anomalous examples\n",
        "  - train algorithm on training set\n",
        "  - Use cross validation set to tune $œµ, x_j$\n",
        "  - test with the test set\n",
        "\n",
        "#### Anomaly detection vs Supervised learning\n",
        "- Anomaly detection is good when\n",
        "  - We have very small number of positive examples and large number of negative examples\n",
        "  - there are many different types of anomalies and future anomalies are not similar to training set anomalies\n",
        "  - Examples : fraud detection, finding new defects in manufacturing, monitoring machines in a data center\n",
        "- Supervised learning is good when\n",
        "  - There are large number of positive and negative examples\n",
        "  - there are enough positive examples and future positive examples are likely to be similar to ones in the training set\n",
        "  - Examples : Email spam classification, Finding known previously seen defects, Diseases classification, Weather prediction\n",
        "\n",
        "#### Choosing what features to use\n",
        "- Non-gaussian features\n",
        "  - Transform to gaussian\n",
        "- Error analysis for anomaly detection\n"
      ],
      "metadata": {
        "id": "gK21q0KLR_E1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender systems\n",
        "- Taking example of predicting the rating a user gives to a specific movie based on the ratings they gave to other movies based on the features of the movies\n",
        "- Notation\n",
        "  - r(i,j) = 1 if user j has rated movie i (0 otherwise)\n",
        "  - $y^{(i,j)}$ ; rating given by user j on movie i (if rated)\n",
        "  - $w^{(j)}, b^{(j)}$ ; parameters for user j\n",
        "  - $x^{(i)}$ ; feature vector for movie i\n",
        "  - For user j and movie i, predict rating : $w^{(j)}.x^{(i)}+ b^{(j)}$\n",
        "  - $m^{(j)}$ ; number of movies rated by user j\n",
        "  - to learn $w^{(j)}, b^{(j)}$, we minimize the cost function below\n",
        "  - Cost function $J(w^{(j)}, b^{(j)}) = \\frac{1}{2m^{(j)}}‚àë_{i:r(i,j)=1}(w^{(j)}.x^{(i)}+ b^{(j)}-y^{(i,j)})^2 + \\frac{Œª}{2m^{(j)}}‚àë_{k=1}^n(w_k^{(j)})^2$\n",
        "  - To learn parameters for all users Cost function $J(w^{(1)}, ..., w^{(n_u)}, b^{(1)}, ..., b^{(n_u)}) = \\frac{1}{2m^{(j)}}‚àë_{j=1}^{n_u} ‚àë_{i:r(i,j)=1}(w^{(j)}.x^{(i)}+ b^{(j)}-y^{(i,j)})^2 + \\frac{Œª}{2m^{(j)}}‚àë_{j=1}^{n_u} ‚àë_{k=1}^n(w_k^{(j)})^2$\n",
        "\n",
        "#### Collaborative filtering algorithm\n",
        "- If we know the w,b and don't have the features, then we can use this to create the features\n",
        "- The cost function will be same as above but it will be a function of x instead of w,b\n",
        "- then combining both cost functions J(w,b) and J(x) will give collaborative filtering cost function\n",
        "- $J(w,b,x) = \\frac{1}{2} ‚àë_{i:r(i,j)=1}(w^{(j)}.x^{(i)}+ b^{(j)}-y^{(i,j)})^2 + \\frac{Œª}{2}‚àë_{j=1}^{n_u} ‚àë_{k=1}^n(w_k^{(j)})^2 + \\frac{Œª}{2}‚àë_{i=1}^{n_m} ‚àë_{k=1}^n(x_k^{(i)})^2$\n",
        "- Minimize the cost function using gradient descent\n",
        "  - repeat\n",
        "  - $w_i^{(j)} = w_i^{(j)} - Œ±\\frac{‚àÇ}{‚àÇw_i^{(j)}}J(w,b,x)$\n",
        "  - $b^{(j)} = b^{(j)} - Œ±\\frac{‚àÇ}{‚àÇb^{(j)}}J(w,b,x)$\n",
        "  - $x_k^{(i)} = x_k^{(i)} - Œ±\\frac{‚àÇ}{‚àÇx_k^{(i)}}J(w,b,x)$\n",
        "\n",
        "#### Binary labels : favs, likes and clicks\n",
        "- For such usecases, we'll build on binary classification instead of using regression\n",
        "- $f_{(w,b,x)}(x)=g(w^{(j)}.x^{(i)}+b^{(j)}) = \\frac{1}{1+e^{w^{(j)}.x^{(i)}+b^{(j)}}}$\n",
        "- Cost function\n",
        "  - $L(f_{(w,b,x)}(x),y^{(i,j)}) = -y^{(i,j)}log(f_{(w,b,x)}(x))-(1-y^{(i,j)})log(1-f_{(w,b,x)}(x))$\n",
        "  - $J(w,b,x) = ‚àë_{(i,j):r(i,j)=1}L(f_{(w,b,x)}(x),y^{(i,j)})$\n",
        "\n",
        "#### Limitations of Collaborative filtering\n",
        "- Cold start probelm.\n",
        "  - How to rank new items that few users have rated?\n",
        "  - How to show something reasonalbe to new users who have rated few items?\n",
        "- Use side information about items or users\n",
        "  - Item : Genre, movie stars, studio, .....\n",
        "  - User : Demographics (age, gender, location), expressed preferences, .....\n",
        "  "
      ],
      "metadata": {
        "id": "essD9y74pE_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow implementation of collaborative filtering\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-1)\n",
        "\n",
        "iterations=200\n",
        "for iter in range(iterations):\n",
        "  with tf.GradientTape() as tape:\n",
        "    cost_value = cofiCostFuncV(X, W, b, Ynorm, R, num_users, num_movies, lambda)\n",
        "\n",
        "  grads = tape.gradient(cost_value, [X,W,b])\n",
        "  optimizer.apply_gradients(zip(grads, [X,W,b]))\n",
        "\n"
      ],
      "metadata": {
        "id": "Gk9uLSdICTPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content-based filtering type of recommender system\n",
        "\n",
        "#### Collaborative filtering vs Content-based filtering\n",
        "- Collaborative filtering recommend items based on ratings of users who gave similar ratings as you\n",
        "- Content based filtering recommend items based on features of user and item to find good match\n",
        "- $V_u^{(j)}$ : is a vector of numbers computed from list of features $X_u^{(j)}$ of user j\n",
        "- $V_m^{(i)}$ : is a vector of numbers computed from list of features $X_m^{(i)}$ of movie i\n",
        "- Dot product of the above two will be a good prediction of rating of user j on movie i\n",
        "\n",
        "#### Deep learning for content-based filtering\n",
        "- To compute $V_u$ from $X_u$ we'll use one neural network and to compute $V_m$ from $X_m$ we'll use another neural network\n",
        "- Prediction : $V_u . V_m$\n",
        "- Cost function $J = ‚àë_{(i,j):r(i,j)=1}(v_u^{(j)}.v_m^{(i)} - y^{(i,j)})^2$ + NN regularization term\n",
        "\n",
        "\n",
        "#### Recommending from a large catalogue\n",
        "- How to efficiently find recommendation from a large set of items\n",
        "  - 1000+ movies, 1m+ songs, 10m+ products etc\n",
        "  - Two steps\n",
        "    - Retrieval\n",
        "      - Generate large list of plausible item candidates\n",
        "      - eg : For each of the last 10 movies watched by the user, find 10 most similar movies, for most viewed 3 genres find the top 10 movies, top 20 movies in the country\n",
        "      - Combine retrieved items into list, removing duplicates and items already watched/purchased\n",
        "    - Ranking\n",
        "      - Take list retrieved and rank using learned model\n",
        "      - Display ranked items to user\n",
        "\n"
      ],
      "metadata": {
        "id": "a1oF1cgEJuhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow implementation of Content-based filtering\n",
        "\n",
        "# Implementing user network and movie network separately\n",
        "user_NN = tf.keras.models.Sequential({\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(32)\n",
        "})\n",
        "\n",
        "item_NN = tf.keras.models.Sequential({\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(32)\n",
        "})\n",
        "\n",
        "# Create the user input and point to the base network\n",
        "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
        "vu = user_NN(input_user)\n",
        "vu = tf.linalg.12_normalize(vu, axis=1)\n",
        "\n",
        "# Create the uitemser input and point to the base network\n",
        "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
        "vm = user_NN(input_item)\n",
        "vm = tf.linalg.12_normalize(vm, axis=1)\n",
        "\n",
        "# Measure the similarity of the two vector outputs\n",
        "output = tf.keras.layers.Dot(axes=1) ([vu,vm])\n",
        "\n",
        "# Specify the inputs and output of the model\n",
        "model = Model([input_user, input_item], output)\n",
        "\n",
        "# Specify the cost function\n",
        "cost_fn = tf.keras.losses.MeanSquaredError()\n"
      ],
      "metadata": {
        "id": "NAZTNzaxinLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Principal Component Analysis\n",
        "- Algorithm usually used for visualization\n",
        "- If we have a large number of features, it will be hard to visualize, so PCA will compress them to few features so that they can be plotted and visualized."
      ],
      "metadata": {
        "id": "_3skEtQRw7kS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement learning\n",
        "- State --> action --> Reward --> New State\n",
        "- reward function : Instead of providing the actual output for a given input like in supervised learning, in reinforcement learning we define a reward function which rewards or penalizes based on the model prediction\n",
        "  - positive reward : +1\n",
        "  - negative reward : -1000\n",
        "- Applications\n",
        "  - Controlling robots\n",
        "  - Factory optimization\n",
        "  - Financial stock trading\n",
        "  - Playing games (including video games)\n",
        "- The return\n",
        "  - Find which reward is more attractive\n",
        "  - Return = $R_1 + Œ≥.R_2 + Œ≥^2.R_3 + .... until terminal state$\n",
        "  - Œ≥ is the discount factor\n",
        "- Making decisions - Markov Decision Process (MDP)\n",
        "  - $State(s) --> Policy(œÄ) --> action(a)$\n",
        "  - Goal of reinforcement learning is to find a policy that tell what action to take in every state so as to maximize the return\n",
        "\n",
        "### State-action value function\n",
        "-"
      ],
      "metadata": {
        "id": "19LT6CN74-gc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "SampleJupyterNotebook",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}